{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fbdh1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>dD1</th>\n",
       "      <th>dD2</th>\n",
       "      <th>dP1</th>\n",
       "      <th>dP2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.69</td>\n",
       "      <td>99.49</td>\n",
       "      <td>-145.71</td>\n",
       "      <td>48.04</td>\n",
       "      <td>-15.90</td>\n",
       "      <td>81.17</td>\n",
       "      <td>12.26</td>\n",
       "      <td>36.71</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.23</td>\n",
       "      <td>172.78</td>\n",
       "      <td>-118.66</td>\n",
       "      <td>79.84</td>\n",
       "      <td>-11.94</td>\n",
       "      <td>80.09</td>\n",
       "      <td>18.49</td>\n",
       "      <td>35.48</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.54</td>\n",
       "      <td>242.66</td>\n",
       "      <td>-81.28</td>\n",
       "      <td>109.77</td>\n",
       "      <td>-7.75</td>\n",
       "      <td>75.74</td>\n",
       "      <td>24.65</td>\n",
       "      <td>33.03</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.17</td>\n",
       "      <td>316.42</td>\n",
       "      <td>-55.50</td>\n",
       "      <td>140.84</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>74.07</td>\n",
       "      <td>28.43</td>\n",
       "      <td>31.89</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.51</td>\n",
       "      <td>392.40</td>\n",
       "      <td>-31.67</td>\n",
       "      <td>171.92</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>73.96</td>\n",
       "      <td>29.70</td>\n",
       "      <td>31.32</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Flow      D1      D2      P1     P2    dD1    dD2    dP1   dP2\n",
       "0 -16.69   99.49 -145.71   48.04 -15.90  81.17  12.26  36.71  2.21\n",
       "1 -16.23  172.78 -118.66   79.84 -11.94  80.09  18.49  35.48  2.91\n",
       "2 -15.54  242.66  -81.28  109.77  -7.75  75.74  24.65  33.03  3.26\n",
       "3 -15.17  316.42  -55.50  140.84  -5.30  74.07  28.43  31.89  3.37\n",
       "4 -14.51  392.40  -31.67  171.92  -1.24  73.96  29.70  31.32  3.68"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label < -7.5:\n",
    "        return 0\n",
    "    elif label > 7.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['Class'] = df['Flow'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>dD1</th>\n",
       "      <th>dD2</th>\n",
       "      <th>dP1</th>\n",
       "      <th>dP2</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.69</td>\n",
       "      <td>99.49</td>\n",
       "      <td>-145.71</td>\n",
       "      <td>48.04</td>\n",
       "      <td>-15.90</td>\n",
       "      <td>81.17</td>\n",
       "      <td>12.26</td>\n",
       "      <td>36.71</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.23</td>\n",
       "      <td>172.78</td>\n",
       "      <td>-118.66</td>\n",
       "      <td>79.84</td>\n",
       "      <td>-11.94</td>\n",
       "      <td>80.09</td>\n",
       "      <td>18.49</td>\n",
       "      <td>35.48</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.54</td>\n",
       "      <td>242.66</td>\n",
       "      <td>-81.28</td>\n",
       "      <td>109.77</td>\n",
       "      <td>-7.75</td>\n",
       "      <td>75.74</td>\n",
       "      <td>24.65</td>\n",
       "      <td>33.03</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.17</td>\n",
       "      <td>316.42</td>\n",
       "      <td>-55.50</td>\n",
       "      <td>140.84</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>74.07</td>\n",
       "      <td>28.43</td>\n",
       "      <td>31.89</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.51</td>\n",
       "      <td>392.40</td>\n",
       "      <td>-31.67</td>\n",
       "      <td>171.92</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>73.96</td>\n",
       "      <td>29.70</td>\n",
       "      <td>31.32</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Flow      D1      D2      P1     P2    dD1    dD2    dP1   dP2  Class\n",
       "0 -16.69   99.49 -145.71   48.04 -15.90  81.17  12.26  36.71  2.21      0\n",
       "1 -16.23  172.78 -118.66   79.84 -11.94  80.09  18.49  35.48  2.91      0\n",
       "2 -15.54  242.66  -81.28  109.77  -7.75  75.74  24.65  33.03  3.26      0\n",
       "3 -15.17  316.42  -55.50  140.84  -5.30  74.07  28.43  31.89  3.37      0\n",
       "4 -14.51  392.40  -31.67  171.92  -1.24  73.96  29.70  31.32  3.68      0"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Matrix / Gather Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1)\n",
    "X.drop('Flow', axis = 1, inplace = True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "scaled_features = scaler.transform(X)\n",
    "X = pd.DataFrame(scaled_features, columns = X.columns[:])\n",
    "\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuts data into length evenly divisible by the window sizes\n",
    "\n",
    "def windowSize(data):\n",
    "    \n",
    "    window = 15\n",
    "    \n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "    new_data = data\n",
    "    \n",
    "    for i in range(len(new_data) - window, len(new_data)):\n",
    "        \n",
    "        if i % window == 0:\n",
    "            new_data = data.truncate(after = i - 1)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates Classifiers for each window based on mode of that window\n",
    "\n",
    "def classWindow(data):\n",
    "    \n",
    "    Class = []\n",
    "    \n",
    "    for i in range(0, len(data), 15):\n",
    "        \n",
    "        Class.append(int(data[i:i+1].mode()))\n",
    "        \n",
    "    return pd.DataFrame(Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = classWindow(windowSize(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = windowSize(X_train).values.reshape(int(len(windowSize(X_train))/15), 15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 15, 8)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 175)               128800    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 175)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                8800      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 137,753\n",
      "Trainable params: 137,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "time_steps = trainX.shape[1]\n",
    "features = trainX.shape[2]\n",
    "\n",
    "LSTM = keras.Sequential()\n",
    "LSTM.add(keras.layers.LSTM(175, input_shape = (time_steps, features)))\n",
    "LSTM.add(keras.layers.Dropout(0.3))\n",
    "LSTM.add(keras.layers.Dense(50, activation = tf.nn.relu))\n",
    "LSTM.add(keras.layers.Dropout(0.4))\n",
    "LSTM.add(keras.layers.Dense(3, activation = tf.nn.softmax))\n",
    "LSTM.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "310/310 [==============================] - 1s 2ms/sample - loss: 1.0878 - acc: 0.3581\n",
      "Epoch 2/50\n",
      "310/310 [==============================] - 0s 447us/sample - loss: 1.0769 - acc: 0.3194\n",
      "Epoch 3/50\n",
      "310/310 [==============================] - 0s 450us/sample - loss: 1.0464 - acc: 0.4774\n",
      "Epoch 4/50\n",
      "310/310 [==============================] - 0s 445us/sample - loss: 1.0304 - acc: 0.4613\n",
      "Epoch 5/50\n",
      "310/310 [==============================] - 0s 444us/sample - loss: 1.0262 - acc: 0.4742\n",
      "Epoch 6/50\n",
      "310/310 [==============================] - 0s 451us/sample - loss: 1.0218 - acc: 0.4613\n",
      "Epoch 7/50\n",
      "310/310 [==============================] - 0s 454us/sample - loss: 0.9882 - acc: 0.5452\n",
      "Epoch 8/50\n",
      "310/310 [==============================] - 0s 451us/sample - loss: 0.9686 - acc: 0.5710\n",
      "Epoch 9/50\n",
      "310/310 [==============================] - 0s 439us/sample - loss: 0.9685 - acc: 0.5548\n",
      "Epoch 10/50\n",
      "310/310 [==============================] - 0s 440us/sample - loss: 0.9239 - acc: 0.5645\n",
      "Epoch 11/50\n",
      "310/310 [==============================] - 0s 451us/sample - loss: 0.9368 - acc: 0.5839\n",
      "Epoch 12/50\n",
      "310/310 [==============================] - 0s 443us/sample - loss: 0.9002 - acc: 0.5774\n",
      "Epoch 13/50\n",
      "310/310 [==============================] - 0s 450us/sample - loss: 0.9051 - acc: 0.5839\n",
      "Epoch 14/50\n",
      "310/310 [==============================] - 0s 451us/sample - loss: 0.9021 - acc: 0.5871\n",
      "Epoch 15/50\n",
      "310/310 [==============================] - 0s 450us/sample - loss: 0.8292 - acc: 0.6516\n",
      "Epoch 16/50\n",
      "310/310 [==============================] - 0s 453us/sample - loss: 0.7919 - acc: 0.6452\n",
      "Epoch 17/50\n",
      "310/310 [==============================] - 0s 452us/sample - loss: 0.8268 - acc: 0.6129\n",
      "Epoch 18/50\n",
      "310/310 [==============================] - 0s 446us/sample - loss: 0.7816 - acc: 0.6387\n",
      "Epoch 19/50\n",
      "310/310 [==============================] - 0s 452us/sample - loss: 0.7715 - acc: 0.6484\n",
      "Epoch 20/50\n",
      "310/310 [==============================] - 0s 458us/sample - loss: 0.8160 - acc: 0.6581\n",
      "Epoch 21/50\n",
      "310/310 [==============================] - 0s 448us/sample - loss: 0.7403 - acc: 0.6774\n",
      "Epoch 22/50\n",
      "310/310 [==============================] - 0s 445us/sample - loss: 0.7468 - acc: 0.6677\n",
      "Epoch 23/50\n",
      "310/310 [==============================] - 0s 443us/sample - loss: 0.6867 - acc: 0.7032\n",
      "Epoch 24/50\n",
      "310/310 [==============================] - 0s 450us/sample - loss: 0.6591 - acc: 0.6968\n",
      "Epoch 25/50\n",
      "310/310 [==============================] - 0s 447us/sample - loss: 0.6041 - acc: 0.7387\n",
      "Epoch 26/50\n",
      "310/310 [==============================] - 0s 454us/sample - loss: 0.6231 - acc: 0.7290\n",
      "Epoch 27/50\n",
      "310/310 [==============================] - 0s 454us/sample - loss: 0.5997 - acc: 0.7452\n",
      "Epoch 28/50\n",
      "310/310 [==============================] - 0s 458us/sample - loss: 0.5856 - acc: 0.7226\n",
      "Epoch 29/50\n",
      "310/310 [==============================] - 0s 447us/sample - loss: 0.6124 - acc: 0.7129\n",
      "Epoch 30/50\n",
      "310/310 [==============================] - 0s 450us/sample - loss: 0.5733 - acc: 0.7129\n",
      "Epoch 31/50\n",
      "310/310 [==============================] - 0s 469us/sample - loss: 0.5469 - acc: 0.7613\n",
      "Epoch 32/50\n",
      "310/310 [==============================] - 0s 520us/sample - loss: 0.5109 - acc: 0.7774\n",
      "Epoch 33/50\n",
      "310/310 [==============================] - 0s 498us/sample - loss: 0.4847 - acc: 0.7774\n",
      "Epoch 34/50\n",
      "310/310 [==============================] - 0s 529us/sample - loss: 0.4451 - acc: 0.8226\n",
      "Epoch 35/50\n",
      "310/310 [==============================] - 0s 524us/sample - loss: 0.4480 - acc: 0.8129\n",
      "Epoch 36/50\n",
      "310/310 [==============================] - 0s 528us/sample - loss: 0.4519 - acc: 0.8097\n",
      "Epoch 37/50\n",
      "310/310 [==============================] - 0s 492us/sample - loss: 0.4137 - acc: 0.8419\n",
      "Epoch 38/50\n",
      "310/310 [==============================] - 0s 502us/sample - loss: 0.3729 - acc: 0.8484\n",
      "Epoch 39/50\n",
      "310/310 [==============================] - 0s 537us/sample - loss: 0.3439 - acc: 0.8710\n",
      "Epoch 40/50\n",
      "310/310 [==============================] - 0s 513us/sample - loss: 0.3437 - acc: 0.8806\n",
      "Epoch 41/50\n",
      "310/310 [==============================] - 0s 502us/sample - loss: 0.3456 - acc: 0.8903\n",
      "Epoch 42/50\n",
      "310/310 [==============================] - 0s 501us/sample - loss: 0.3586 - acc: 0.8323\n",
      "Epoch 43/50\n",
      "310/310 [==============================] - 0s 492us/sample - loss: 0.3364 - acc: 0.8452\n",
      "Epoch 44/50\n",
      "310/310 [==============================] - 0s 488us/sample - loss: 0.2770 - acc: 0.8968\n",
      "Epoch 45/50\n",
      "310/310 [==============================] - 0s 538us/sample - loss: 0.2904 - acc: 0.8839\n",
      "Epoch 46/50\n",
      "310/310 [==============================] - 0s 544us/sample - loss: 0.2531 - acc: 0.8871\n",
      "Epoch 47/50\n",
      "310/310 [==============================] - 0s 606us/sample - loss: 0.2518 - acc: 0.9032\n",
      "Epoch 48/50\n",
      "310/310 [==============================] - 0s 569us/sample - loss: 0.2235 - acc: 0.8871\n",
      "Epoch 49/50\n",
      "310/310 [==============================] - 0s 466us/sample - loss: 0.2187 - acc: 0.9129\n",
      "Epoch 50/50\n",
      "310/310 [==============================] - 0s 430us/sample - loss: 0.2270 - acc: 0.9258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a43029320>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM.fit(trainX, trainY, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model on Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = windowSize(X_test).values.reshape(int(len(windowSize(X_test)) / 15), 15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = classWindow(windowSize(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 15, 8)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 1)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = LSTM.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76        62\n",
      "           1       0.60      0.79      0.68        43\n",
      "           2       0.45      0.36      0.40        28\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       133\n",
      "   macro avg       0.62      0.62      0.61       133\n",
      "weighted avg       0.67      0.66      0.66       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_pred = []\n",
    "for score in range(0, len(predictions)):\n",
    "    final_pred.append(np.argmax(predictions[score]))\n",
    "    \n",
    "print(classification_report(testY, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataframe\n",
    "test = pd.read_csv('test_data_2.csv')\n",
    "test['Class'] = test['Flow'].apply(label_fix)\n",
    "\n",
    "# Create the Feature Matrix and Scale Features\n",
    "X_1 = test.drop('Class', axis = 1)\n",
    "X_1.drop('Flow', axis = 1, inplace = True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_1)\n",
    "scaled_features = scaler.transform(X_1)\n",
    "X_1 = pd.DataFrame(scaled_features, columns = X_1.columns[:])\n",
    "\n",
    "# Create the classification matrix\n",
    "y_1 = test['Class']\n",
    "\n",
    "X_LSTM = X_1.values.reshape(5019, 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88      2145\n",
      "           1       0.87      0.89      0.88      2074\n",
      "           2       0.73      0.64      0.68       800\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5019\n",
      "   macro avg       0.82      0.81      0.81      5019\n",
      "weighted avg       0.85      0.85      0.85      5019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = LSTM.predict(X_LSTM)\n",
    "\n",
    "final_pred_test = []\n",
    "for score in range(0, len(test_predictions)):\n",
    "    final_pred_test.append(np.argmax(test_predictions[score]))\n",
    "    \n",
    "print(classification_report(y_1, final_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
