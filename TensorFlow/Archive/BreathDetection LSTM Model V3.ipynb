{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Dataset and Add Class Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fbdh1.csv')\n",
    "\n",
    "def label_fix(label):\n",
    "    if label < -7.5:\n",
    "        return 0\n",
    "    elif label > 7.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['Class'] = df['Flow'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Matrix / Gather Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Feature Matrix and Scale Features\n",
    "X = df.drop('Class', axis = 1)\n",
    "X.drop('Flow', axis = 1, inplace = True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "scaled_features = scaler.transform(X)\n",
    "X = pd.DataFrame(scaled_features, columns = X.columns[:])\n",
    "\n",
    "# Create the classification matrix\n",
    "y = df['Class']\n",
    "\n",
    "# Perform train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>dD1</th>\n",
       "      <th>dD2</th>\n",
       "      <th>dP1</th>\n",
       "      <th>dP2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1.178579</td>\n",
       "      <td>-0.223814</td>\n",
       "      <td>1.192568</td>\n",
       "      <td>-0.283248</td>\n",
       "      <td>0.957240</td>\n",
       "      <td>0.136326</td>\n",
       "      <td>0.916936</td>\n",
       "      <td>0.280479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6593</th>\n",
       "      <td>-1.569557</td>\n",
       "      <td>-0.162236</td>\n",
       "      <td>-1.524327</td>\n",
       "      <td>-0.240768</td>\n",
       "      <td>-0.095965</td>\n",
       "      <td>-0.015353</td>\n",
       "      <td>-0.112203</td>\n",
       "      <td>0.010169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>1.512751</td>\n",
       "      <td>0.171241</td>\n",
       "      <td>1.676542</td>\n",
       "      <td>0.905516</td>\n",
       "      <td>-0.986103</td>\n",
       "      <td>-0.696264</td>\n",
       "      <td>-0.943607</td>\n",
       "      <td>-0.842346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>-0.638754</td>\n",
       "      <td>0.231635</td>\n",
       "      <td>-0.537954</td>\n",
       "      <td>0.388277</td>\n",
       "      <td>-1.471377</td>\n",
       "      <td>-0.593027</td>\n",
       "      <td>-1.500482</td>\n",
       "      <td>-0.792762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1.068579</td>\n",
       "      <td>0.245603</td>\n",
       "      <td>1.131168</td>\n",
       "      <td>0.541318</td>\n",
       "      <td>-0.334582</td>\n",
       "      <td>0.244668</td>\n",
       "      <td>-0.308558</td>\n",
       "      <td>0.402038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            D1        D2        P1        P2       dD1       dD2       dP1  \\\n",
       "444   1.178579 -0.223814  1.192568 -0.283248  0.957240  0.136326  0.916936   \n",
       "6593 -1.569557 -0.162236 -1.524327 -0.240768 -0.095965 -0.015353 -0.112203   \n",
       "4568  1.512751  0.171241  1.676542  0.905516 -0.986103 -0.696264 -0.943607   \n",
       "3604 -0.638754  0.231635 -0.537954  0.388277 -1.471377 -0.593027 -1.500482   \n",
       "954   1.068579  0.245603  1.131168  0.541318 -0.334582  0.244668 -0.308558   \n",
       "\n",
       "           dP2  \n",
       "444   0.280479  \n",
       "6593  0.010169  \n",
       "4568 -0.842346  \n",
       "3604 -0.792762  \n",
       "954   0.402038  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4664/53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM input\n",
    "X_train_LSTM = X_train.values.reshape(88, 53, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 53, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_LSTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4664 into shape (88,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4a02b1c61f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train_LSTM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4664 into shape (88,1)"
     ]
    }
   ],
   "source": [
    "y_train_LSTM = y_train.values.reshape(88, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4664, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_LSTM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 175)               128800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 175)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                8800      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 137,753\n",
      "Trainable params: 137,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM = keras.Sequential()\n",
    "LSTM.add(keras.layers.LSTM(175, input_shape = (1, 8)))\n",
    "LSTM.add(keras.layers.Dropout(0.3))\n",
    "LSTM.add(keras.layers.Dense(50, activation = tf.nn.relu))\n",
    "LSTM.add(keras.layers.Dropout(0.4))\n",
    "LSTM.add(keras.layers.Dense(3, activation = tf.nn.softmax))\n",
    "LSTM.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0912 11:13:07.054593 4673078720 deprecation.py:323] From /Users/mikefurr/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4664/4664 [==============================] - 1s 165us/sample - loss: 0.6058 - acc: 0.7867\n",
      "Epoch 2/50\n",
      "4664/4664 [==============================] - 0s 69us/sample - loss: 0.3760 - acc: 0.8497\n",
      "Epoch 3/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.3501 - acc: 0.8587\n",
      "Epoch 4/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.3285 - acc: 0.8703\n",
      "Epoch 5/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.3182 - acc: 0.8714\n",
      "Epoch 6/50\n",
      "4664/4664 [==============================] - 0s 67us/sample - loss: 0.3071 - acc: 0.8806\n",
      "Epoch 7/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.3056 - acc: 0.8804\n",
      "Epoch 8/50\n",
      "4664/4664 [==============================] - 0s 67us/sample - loss: 0.2967 - acc: 0.8859\n",
      "Epoch 9/50\n",
      "4664/4664 [==============================] - 0s 67us/sample - loss: 0.2956 - acc: 0.8883\n",
      "Epoch 10/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2905 - acc: 0.8881\n",
      "Epoch 11/50\n",
      "4664/4664 [==============================] - 0s 67us/sample - loss: 0.2854 - acc: 0.8928\n",
      "Epoch 12/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2815 - acc: 0.8954\n",
      "Epoch 13/50\n",
      "4664/4664 [==============================] - 0s 67us/sample - loss: 0.2835 - acc: 0.8911\n",
      "Epoch 14/50\n",
      "4664/4664 [==============================] - 0s 69us/sample - loss: 0.2810 - acc: 0.8932\n",
      "Epoch 15/50\n",
      "4664/4664 [==============================] - 0s 67us/sample - loss: 0.2763 - acc: 0.8945\n",
      "Epoch 16/50\n",
      "4664/4664 [==============================] - 0s 69us/sample - loss: 0.2774 - acc: 0.8945\n",
      "Epoch 17/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2750 - acc: 0.8958\n",
      "Epoch 18/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2743 - acc: 0.8943\n",
      "Epoch 19/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2683 - acc: 0.8945\n",
      "Epoch 20/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2713 - acc: 0.8979\n",
      "Epoch 21/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2687 - acc: 0.8952\n",
      "Epoch 22/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2696 - acc: 0.8994\n",
      "Epoch 23/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2681 - acc: 0.8954\n",
      "Epoch 24/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2719 - acc: 0.8952\n",
      "Epoch 25/50\n",
      "4664/4664 [==============================] - 0s 68us/sample - loss: 0.2726 - acc: 0.8958\n",
      "Epoch 26/50\n",
      "4664/4664 [==============================] - 0s 69us/sample - loss: 0.2628 - acc: 0.8990\n",
      "Epoch 27/50\n",
      "4664/4664 [==============================] - 0s 69us/sample - loss: 0.2678 - acc: 0.8994\n",
      "Epoch 28/50\n",
      "4664/4664 [==============================] - 0s 70us/sample - loss: 0.2620 - acc: 0.8973\n",
      "Epoch 29/50\n",
      "4664/4664 [==============================] - 0s 70us/sample - loss: 0.2670 - acc: 0.8964\n",
      "Epoch 30/50\n",
      "4664/4664 [==============================] - 0s 71us/sample - loss: 0.2677 - acc: 0.9005\n",
      "Epoch 31/50\n",
      "4664/4664 [==============================] - 0s 79us/sample - loss: 0.2643 - acc: 0.8958\n",
      "Epoch 32/50\n",
      "4664/4664 [==============================] - 0s 71us/sample - loss: 0.2615 - acc: 0.9009\n",
      "Epoch 33/50\n",
      "4664/4664 [==============================] - 0s 70us/sample - loss: 0.2638 - acc: 0.8962\n",
      "Epoch 34/50\n",
      "4664/4664 [==============================] - 0s 70us/sample - loss: 0.2626 - acc: 0.8997\n",
      "Epoch 35/50\n",
      "4664/4664 [==============================] - 0s 72us/sample - loss: 0.2615 - acc: 0.8973\n",
      "Epoch 36/50\n",
      "4664/4664 [==============================] - 0s 71us/sample - loss: 0.2606 - acc: 0.8990\n",
      "Epoch 37/50\n",
      "4664/4664 [==============================] - 0s 70us/sample - loss: 0.2622 - acc: 0.8997\n",
      "Epoch 38/50\n",
      "4664/4664 [==============================] - 0s 72us/sample - loss: 0.2637 - acc: 0.8964\n",
      "Epoch 39/50\n",
      "4664/4664 [==============================] - 0s 72us/sample - loss: 0.2561 - acc: 0.8977\n",
      "Epoch 40/50\n",
      "4664/4664 [==============================] - 0s 70us/sample - loss: 0.2619 - acc: 0.8992\n",
      "Epoch 41/50\n",
      "4664/4664 [==============================] - 0s 71us/sample - loss: 0.2628 - acc: 0.8990\n",
      "Epoch 42/50\n",
      "4664/4664 [==============================] - 0s 70us/sample - loss: 0.2600 - acc: 0.8986\n",
      "Epoch 43/50\n",
      "4664/4664 [==============================] - 0s 71us/sample - loss: 0.2636 - acc: 0.8973\n",
      "Epoch 44/50\n",
      "4664/4664 [==============================] - 0s 74us/sample - loss: 0.2590 - acc: 0.8992\n",
      "Epoch 45/50\n",
      "4664/4664 [==============================] - 0s 71us/sample - loss: 0.2553 - acc: 0.8997\n",
      "Epoch 46/50\n",
      "4664/4664 [==============================] - 0s 71us/sample - loss: 0.2552 - acc: 0.9020\n",
      "Epoch 47/50\n",
      "4664/4664 [==============================] - 0s 73us/sample - loss: 0.2557 - acc: 0.8997\n",
      "Epoch 48/50\n",
      "4664/4664 [==============================] - 0s 72us/sample - loss: 0.2556 - acc: 0.9012\n",
      "Epoch 49/50\n",
      "4664/4664 [==============================] - 0s 72us/sample - loss: 0.2574 - acc: 0.8958\n",
      "Epoch 50/50\n",
      "4664/4664 [==============================] - 0s 73us/sample - loss: 0.2544 - acc: 0.9001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a36c7d5c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM.fit(X_train_LSTM, y_train_LSTM, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model on Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       837\n",
      "           1       0.94      0.93      0.94       801\n",
      "           2       0.73      0.80      0.76       362\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2000\n",
      "   macro avg       0.87      0.88      0.88      2000\n",
      "weighted avg       0.91      0.90      0.90      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_LSTM = X_test.values.reshape(2000, 1, 8)\n",
    "\n",
    "predictions = LSTM.predict(X_test_LSTM)\n",
    "\n",
    "final_pred = []\n",
    "for score in range(0, len(predictions)):\n",
    "    final_pred.append(np.argmax(predictions[score]))\n",
    "    \n",
    "print(classification_report(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataframe\n",
    "test = pd.read_csv('test_data_2.csv')\n",
    "test['Class'] = test['Flow'].apply(label_fix)\n",
    "\n",
    "# Create the Feature Matrix and Scale Features\n",
    "X_1 = test.drop('Class', axis = 1)\n",
    "X_1.drop('Flow', axis = 1, inplace = True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_1)\n",
    "scaled_features = scaler.transform(X_1)\n",
    "X_1 = pd.DataFrame(scaled_features, columns = X_1.columns[:])\n",
    "\n",
    "# Create the classification matrix\n",
    "y_1 = test['Class']\n",
    "\n",
    "X_LSTM = X_1.values.reshape(5019, 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88      2145\n",
      "           1       0.87      0.89      0.88      2074\n",
      "           2       0.73      0.64      0.68       800\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5019\n",
      "   macro avg       0.82      0.81      0.81      5019\n",
      "weighted avg       0.85      0.85      0.85      5019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = LSTM.predict(X_LSTM)\n",
    "\n",
    "final_pred_test = []\n",
    "for score in range(0, len(test_predictions)):\n",
    "    final_pred_test.append(np.argmax(test_predictions[score]))\n",
    "    \n",
    "print(classification_report(y_1, final_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
